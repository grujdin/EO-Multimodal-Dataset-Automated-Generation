## EMDAT Data Processing Pipeline

The following table summarizes all processing operations applied to the raw EM-DAT data, from initial reduction through RDF conversion. Each step reads one or more source files and produces new outputs ready for the next stage.

| Processing Operation                                   | Description                                                                                                                  | Source File(s)                                                                                                                                                                                                    | Destination File(s)                                                                                                                            | Script Name / API          | Remarks                                                                                                                                                                                                                                          |
|:-------------------------------------------------------|:-----------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------|:---------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **REDUCE EM-DAT PUBLIC TABLE**                         | Extract only the columns needed for downstream analysis & reduce file size                                                   | `<home_directory>/emdat_gdis_semantic_connector/Data/public_emdat_custom_request_2025-03-24_1ab022ea-6fe2-42b7-ab52-ce8e32733b4c.xlsx`                                                                                                                       | `<home_directory>/emdat_gdis_semantic_connector/Data/public_emdat_reduced.xlsx`                                                                                                                     | `reduce_emdat.py`         | Retained columns:<br/>`DisNo., Classification Key, External IDs, Event Name, ISO, Country, Subregion, Region, Location, Origin, Associated Types, Latitude, Longitude, River Basin, Start Year, Start Month, Start Day, End Year, End Month, End Day, Admin Units (adm1_code, adm1_name, adm2_code, adm2_name), Entry Date, Last Update` |
| **SPLIT INTO OBSERVATIONS & ALIGN TO GDIS**            | Split multi‐location events into one observation per location; harmonize spellings; assign unique observation IDs (MMR-xxx) | `<home_directory>/emdat_gdis_semantic_connector/Data/public_emdat_reduced.xlsx`                                                                                                                                                                                       | `<home_directory>/emdat_gdis_semantic_connector/Data/public_emdat_gdis_aligned.xlsx`                                                                                                                | `<home_directory>/emdat_gdis_semantic_connector/emdat2gdis.py`           | 1. Fix spelling differences between sources<br/>2. Link observations by `DisNo.`<br/>3. Generate unique IDs (`MMR-xxx`)                                                                                                                       |
| **EXTRACT GAUL GEOMETRIES**                            | Retrieve GAUL ADM1/ADM2 geometries for each observation and store as XML                                                     | `<home_directory>/emdat_gdis_semantic_connector/Data/public_emdat_gdis_aligned.xlsx`,<br/>`<home_directory>/emdat_gdis_semantic_connector/Data/g2015_2014_1.xml`, </br> `<home_directory>/emdat_gdis_semantic_connector/Data/g2015_2014_2.xml`                                                                                                                                      | `<home_directory>/emdat_gdis_semantic_connector/Data/g2015_2014_1_geom_extract.xml`,<br/>`<home_directory>/emdat_gdis_semantic_connector/Data/g2015_2014_2_geom_extract.xml`,<br/>`<home_directory>/emdat_gdis_semantic_connector/Data/public_emdat_gdis_gaul_aligned.xlsx`                                      | `<home_directory>/emdat_gdis_semantic_connector/emdat_gdis2gaul.py`      | Writes one XML per GAUL level and a combined Excel with geometry references                                                                                                                                |
| **ASSIGN GAUL FIDs TO OBSERVATIONS**                   | Map each observation to its GAUL FID_1 and FID_2 feature identifiers                                                                 | `<home_directory>/emdat_gdis_semantic_connector/Data/g2015_2014_1_geom_extract.xml`,<br/>`<home_directory>/emdat_gdis_semantic_connector/Data/g2015_2014_2_geom_extract.xml`,<br/>`<home_directory>/emdat_gdis_semantic_connector/Data/public_emdat_gdis_gaul_aligned.xlsx`                                                                                                       | `<home_directory>/emdat_gdis_semantic_connector/Data/public_emdat_gdis_gaul_fids.xlsx`                                                                                                               | `<home_directory>/emdat_gdis_semantic_connector/emdat_gdis_gaul_wfids.py` | Added columns:<br/>`Unique Code, FID_1, adm1_code, adm1_name, FID_2, adm2_code, adm2_name`                                                                                                                |
| **EXTRACT & DISPLAY ADMIN COMPOSITE IMAGES**           | Build composite images of GAUL units (ADM0→ADM1, ADM1→ADM2, and single ADM2)                                                  | `<home_directory>/emdat_gdis_semantic_connector/Data/g2015_2014_1.xml`, `<home_directory>/emdat_gdis_semantic_connector/Data/g2015_2014_2.xml`                                                                                                                                                                            | `<home_directory>/emdat_gdis_semantic_connector/Data/ADM0_Composite_Images/*.`,<br/>`<home_directory>/emdat_gdis_semantic_connector/Data/ADM1_Composite_Images/`,<br/>`<home_directory>/emdat_gdis_semantic_connector/Data/ADM2_Composite_Images/`                                               | `<home_directory>/emdat_gdis_semantic_connector/Data/CompositeImages_ADM0.py`<br/>`<home_directory>/emdat_gdis_semantic_connector/CompositeImages_ADM1.py`<br/>`<home_directory>/emdat_gdis_semantic_connector/CompositeImages_ADM2.py` | Produces one map per administrative unit level for visual QA                                                                                                                                         |
| **CREATE FULL HAZARD TAXONOMY**                        | Generate TTL of the complete hazard hierarchy (EM-DAT aligned) plus sensor/ML–objective concepts                             | `<home_directory>/emdat_gdis_semantic_connector/Data/classification_mapping.csv`                                                                                                                                                                                       | `<home_directory>/emdat_gdis_semantic_connector/Data/hazard_taxonomy.ttl`                                                                                                                            | `Build_hazard_taxonomy.py` | Reads the canonical `key → group,subgroup,type,subtype` CSV and emits RDF classes & `rdfs:subClassOf` triples                                                                                         |
| **CONVERT DISASTER DATA INTO RDF**                     | Transform all events & observations into RDF triples for GraphDB ingestion                                                   | `<home_directory>/emdat_gdis_semantic_connector/Data/public_emdat_GDIS_GAUL_FIDs.xlsx`,<br/>`<home_directory>/emdat_gdis_semantic_connector/Data/classification_mapping.csv`                                                                                                                                                | `<home_directory>/emdat_gdis_semantic_connector/Data/emdat_gdis_gaul_observations_enhanced.ttl`                                                                                                       | `<home_directory>/emdat_gdis_semantic_connector/RDF_Ingestion_Script.py`  | Reads mapping CSV to assign `hasHazardGroup/Subgroup/Type/Subtype` and emits all event/observation triples (dates, locations, QA flags, GAUL links)                                                     |

