# EMDAT-GDIS Semantic Connector Pipeline

The **EMDAT-GDIS Semantic Connector** provides a structured workflow to transform, harmonize, visualize, and semantically annotate disaster event data from the EM-DAT public database. Each step aligns this data with GDIS spatial units and GAUL administrative boundaries, creating a semantic graph suitable for advanced analysis, visualization, and machine-readable query execution.

## EMDAT Data Processing Pipeline

The following table summarizes all processing operations applied to the raw EM-DAT data, from initial reduction through RDF conversion. Each step reads one or more source files and produces new outputs ready for the next stage.

| Processing Operation | Description | Source File(s) (HOME_DIR/emdat_gdis_semantic_connector/) | Destination File(s) (HOME_DIR/emdat_gdis_semantic_connector/) | Script Name  (HOME_DIR/emdat_gdis_semantic_connector/) | Remarks |
|:--------------------|:------------|:----------------|:---------------------|:------------------|:--------|
| **REDUCE EM-DAT PUBLIC TABLE** | Extract required columns to reduce file size and retain relevant metadata | <ul><li>`data/public_emdat_custom_request_2024-05-12_85ae59a7.xlsx`</li></ul> | <ul><li>`data/emdat_reduced.xlsx`</li></ul> | <ul><li>`reduce_emdat.py`</li></ul> | Retains EM-DAT metadata (hazard, time, location, identifiers, coordinates, admin units) |
| **SPLIT INTO OBSERVATIONS & ALIGN TO GDIS** | Split multi-location records, normalize names, and assign unique `MMR-xxx` codes | <ul><li>`data/emdat_reduced.xlsx`</li></ul> | <ul><li>`data/emdat_ev2obs.xlsx`</li></ul> | <ul><li>`split_ev2obs.py`</li></ul> | Includes fuzzy matching logic and expansion of regional naming structures |
| **EXTRACT GAUL GEOMETRIES** | Retrieve and trim GAUL XML geometries (ADM1/ADM2) corresponding to event locations | <ul><li>`data/emdat_ev2obs.xlsx`</li><li>`data/g2015_2014_1.xml`</li><li>`data/g2015_2014_2.xml`</li></ul> | <ul><li>`data/g2015_2014_1_geom_extract.xml`</li><li>`data/g2015_2014_2_geom_extract.xml`</li><li>`data/emdat_obs2gaul.xlsx`</li></ul> | <ul><li>`emdat_obs2gaul.py`</li></ul> | Selectively extracts only the referenced GAUL features for further analysis |
| **ASSIGN GAUL FIDs TO OBSERVATIONS** | Map observations to GAUL geometries by FID and update event records | <ul><li>`data/g2015_2014_1_geom_extract.xml`</li><li>`data/g2015_2014_2_geom_extract.xml`</li><li>`data/emdat_obs2gaul.xlsx`</li></ul> | <ul><li>`data/emdat_obs2gaul_geom.xlsx`</li></ul> | <ul><li>`emdat_obs2gaul_geom.py`</li></ul> | Adds administrative geometry identifiers (FID_1/FID_2) for spatial linkage |
| **EXTRACT & DISPLAY ADMIN COMPOSITE IMAGES** | Build high-resolution composite maps for ADM0 → ADM1 and ADM1 → ADM2 groupings | <ul><li>`data/g2015_2014_1.xml`</li><li>`data/g2015_2014_2.xml`</li></ul> | <ul><li>`data/adm0_composite_maps/*.png`</li><li>`data/adm1_composite_maps/*.png`</li><li>`data/adm2_maps/*.png`</li></ul> | <ul><li>`adm0_composite_map.py`</li><li>`adm1_composite_map.py`</li><li>`adm2_map.py`</li></ul> | Color-coded polygons with adjacency-aware coloring and centroid labels per unit |
| **CREATE FULL HAZARD TAXONOMY** | Build hierarchical hazard taxonomy in OWL-TTL format from classification mapping | <ul><li>`data/classification_mapping.csv`</li></ul> | <ul><li>`data/emdat_hazard_taxonomy.ttl`</li></ul> | <ul><li>`build_emdat_hazard_taxonomy.py`</li></ul> | Includes relationships to sensors and ML-relevant objectives using `isMonitoredBy`, `hasRelatedObjective` |
| **CONVERT DISASTER DATA INTO RDF** | Generate RDF triples for all observations and their related events | <ul><li>`data/emdat_obs2gaul_geom.xlsx`</li><li>`data/classification_mapping.csv`</li></ul> | <ul><li>`data/emdat_obs.ttl`</li></ul> | <ul><li>`obs2rdf.py`</li></ul> | Emits complete RDF graphs with GeoSPARQL, OWL-Time, and hazard ontology alignment |
| **FEED THE DATA INTO LOCAL GRAPHDB** | Load all RDF graphs into local triple store | <ul><li>`data/eomdg_ontology.ttl`</li><li>`data/emdat_hazard_taxonomy.ttl`</li><li>`data/emdat_gdis_gaul_observations.ttl`</li></ul> | <ul><li>SPARQL endpoint: `http://localhost:7200/repositories/eo_nh_kg`</li></ul> | <ul><li>`TBD.py`</li></ul> | Recommended load order: ontology → taxonomy → data instance triples |

---

This pipeline enables spatially and semantically rich analysis of natural disasters using linked data principles, with alignment across EM-DAT metadata, GDIS location descriptors, and GAUL administrative boundaries. It is optimized for high-resolution mapping, ontology-enhanced AI pipelines, and federated SPARQL queries.
